{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f06d4d4c-bdb8-4a28-b592-809bcad67886",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, inputDFs):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2fcffba-ef14-4bc9-803a-66846aa680f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode, col\n",
    "class Task1Transformer(Transformer):\n",
    "\n",
    "    def transform(self, inputDF):\n",
    "        \"\"\"\n",
    "        Distribución de los animes según su género\n",
    "        \"\"\"\n",
    "\n",
    "        # Dividir las cadenas de géneros en listas\n",
    "        anime_df = inputDF.withColumn(\"genre_list\", split(col(\"genre\"), \", \"))\n",
    "\n",
    "        # Explotar las listas para convertir cada elemento en una fila separada\n",
    "        exploded_anime_df = anime_df.withColumn(\"genre\", explode(col(\"genre_list\")))\n",
    "\n",
    "        # Crear vista temporal\n",
    "        exploded_anime_df.createOrReplaceTempView(\"animes\")\n",
    "\n",
    "        task1 = spark.sql(\"\"\" \n",
    "                          SELECT genre, COUNT(*) AS counted\n",
    "                          FROM animes\n",
    "                          GROUP BY genre\n",
    "                          ORDER BY counted DESC\n",
    "                          \"\"\")\n",
    "        return task1\n",
    "\n",
    "class Task2Transformer(Transformer):\n",
    "\n",
    "    def transform(self, inputDF):\n",
    "        \"\"\"\n",
    "            Relación entre puntuación y número de episodio\n",
    "        \"\"\"\n",
    "\n",
    "        anime_df = inputDF.createOrReplaceTempView(\"animes\")\n",
    "\n",
    "        task2 = spark.sql(\"\"\"\n",
    "                          SELECT episodes, AVG(score) AS avg_score\n",
    "                          FROM animes\n",
    "                          GROUP BY episodes\n",
    "                          ORDER BY episodes DESC\n",
    "                          \"\"\")\n",
    "        return task2\n",
    "\n",
    "class Task3Transformer(Transformer):\n",
    "\n",
    "    def transform(self, inputDF):\n",
    "        \"\"\"\n",
    "            Popularidad de los animes a lo largo de los años\n",
    "        \"\"\"\n",
    "\n",
    "        anime_df = inputDF.createOrReplaceTempView(\"animes\")\n",
    "\n",
    "        task3 = spark.sql(\"\"\"\n",
    "                          SELECT aired_from_year, AVG(members) AS avg_members\n",
    "                          FROM animes\n",
    "                          GROUP BY aired_from_year\n",
    "                          ORDER BY aired_from_year DESC\n",
    "                          \"\"\")\n",
    "        return task3\n",
    "    \n",
    "class Task4Transformer(Transformer):\n",
    "\n",
    "    def transform(self, inputsDF):\n",
    "        \"\"\"\n",
    "            Géneros de anime más comúnmente completados por los usuarios\n",
    "        \"\"\"\n",
    "\n",
    "        anime_df = inputsDF.get(\"Anime\")\n",
    "        review_df = inputsDF.get(\"Review\")\n",
    "\n",
    "        # Dividir las cadenas de géneros en listas\n",
    "        anime_df = anime_df.withColumn(\"genre_list\", split(col(\"genre\"), \", \"))\n",
    "\n",
    "        # Explotar las listas para convertir cada elemento en una fila separada\n",
    "        exploded_anime_df = anime_df.withColumn(\"genre\", explode(col(\"genre_list\")))\n",
    "\n",
    "        # Crear vista temporal\n",
    "        exploded_anime_df.createOrReplaceTempView(\"animes\")\n",
    "        review_df.createOrReplaceTempView(\"reviews\")\n",
    "\n",
    "        task3 = spark.sql(\"\"\"\n",
    "                          SELECT a.genre, COUNT(r.my_status) AS count_completed\n",
    "                          FROM animes AS a\n",
    "                          LEFT JOIN reviews AS r\n",
    "                          USING (anime_id)\n",
    "                          WHERE r.my_status = 2\n",
    "                          GROUP BY a.genre\n",
    "                          ORDER BY count_completed DESC\n",
    "                          \"\"\")\n",
    "        return task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c99820a-777c-4637-b007-f9b74d821e22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transformer",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
